{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils import *\n",
    "from dataset import TossingDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddedNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_traj_num, pre_traj_num):\n",
    "        super(EmbeddedNet, self).__init__()\n",
    "        self.hidden_dim = 128\n",
    "        self.fc_1 = nn.Sequential(\n",
    "            nn.Linear(in_traj_num * 2, self.hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.fc_out = nn.Linear(self.hidden_dim, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        parameters = self.fc_out(x)\n",
    "        y_hat = predict_locations(parameters, 3, 15, fps=30.0)\n",
    "\n",
    "        return y_hat, parameters\n",
    "    \n",
    "def predict_locations(parameters, in_frames_num, pre_frames_num, fps):\n",
    "\n",
    "    # Generate t matrix\n",
    "    t_vector = torch.arange(in_frames_num, pre_frames_num + in_frames_num, 1.0).cuda() / fps\n",
    "    t_vector_square = torch.pow(t_vector, 2)\n",
    "    t_matrix = torch.stack((torch.ones(pre_frames_num).cuda(), \n",
    "                            t_vector, \n",
    "                            t_vector_square))\n",
    "\n",
    "     # Get x axis paremeter\n",
    "    x_param = parameters[:, :2]\n",
    "    x_param = torch.cat((x_param, \n",
    "                         torch.ones(x_param.shape[0]).view(-1, 1).cuda() * 0), dim=1)\n",
    "    x_locs_est = torch.mm(x_param, t_matrix)\n",
    "\n",
    "    # Get y axis parameter\n",
    "    y_param = parameters[:, 2:]\n",
    "    \n",
    "    y_param = torch.cat((y_param, torch.ones(y_param.shape[0]).view(-1, 1).cuda() * (-0.5) * 9.8), dim=1)\n",
    "    y_locs_est = torch.mm(y_param, t_matrix)\n",
    "\n",
    "    # Combine results\n",
    "    return torch.cat((x_locs_est, y_locs_est), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs, optimizer, scheduler, criterion):\n",
    "    # Training the Model\n",
    "    min_test_dif = float('inf')\n",
    "    epoch_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        batch_loss = []\n",
    "        for i, data in enumerate(train_loader):\n",
    "            \n",
    "            # get the inputs\n",
    "            inputs = data['current_locs_gt']\n",
    "            locs_gt = data['future_locs_gt']\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            locs_gt = locs_gt.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = criterion(outputs[0], locs_gt)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "        # Results every epoch\n",
    "        cur_epoch_loss = sum(batch_loss) / len(batch_loss)\n",
    "        \n",
    "        # Scheduler\n",
    "        scheduler.step(cur_epoch_loss)\n",
    "        \n",
    "        # Test the network\n",
    "        train_dif = test_model(model, train_loader)\n",
    "        test_dif = test_model(model, test_loader)\n",
    "        \n",
    "        # Print the result\n",
    "        print('Epoch: %d Train Loss: %.03f Train Dif: %.03f Test Dif: %.03f' \n",
    "              % (epoch, cur_epoch_loss, train_dif, test_dif))\n",
    "        epoch_loss.append(cur_epoch_loss)\n",
    "        \n",
    "        if min_test_dif > test_dif:\n",
    "            min_test_dif = test_dif\n",
    "            print('Best')\n",
    "        \n",
    "    return epoch_loss\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    # Test the Model\n",
    "    model.eval()\n",
    "    \n",
    "    batch_loss = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "\n",
    "        # get the inputs\n",
    "        inputs = data['current_locs_gt']\n",
    "        locs_gt = data['future_locs_gt']\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        locs_gt = locs_gt.cuda()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = get_mean_distance(locs_gt, outputs[0])\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "    # Results every epoch\n",
    "    cur_epoch_loss = sum(batch_loss) / len(batch_loss)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    return cur_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################### Hyperparameters ####################\n",
    "num_epochs = 50000\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0\n",
    "in_frames_num = 3\n",
    "pre_frames_num = 15\n",
    "factor = 0.95\n",
    "patience = 40\n",
    "batch_size = 16\n",
    "#################### Hyperparameters ####################\n",
    "net = EmbeddedNet(in_traj_num=3, pre_traj_num=15).cuda()\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_set = TossingDataset(\n",
    "    './dataset/r1_k0.2/train', \n",
    "    in_traj_num=3, \n",
    "    pre_traj_num=15,\n",
    "    sample_num=32\n",
    ")\n",
    "\n",
    "test_set = TossingDataset(\n",
    "    './dataset/r1_k0.2/test', \n",
    "    in_traj_num=3,\n",
    "    pre_traj_num=15\n",
    ")\n",
    "\n",
    "print(len(train_set), len(test_set))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=len(test_set), shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=factor, \n",
    "    patience=patience, \n",
    "    verbose=True, \n",
    "    threshold=1e-3\n",
    ")\n",
    "\n",
    "train_loss = train_model(\n",
    "    net, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    num_epochs, \n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
